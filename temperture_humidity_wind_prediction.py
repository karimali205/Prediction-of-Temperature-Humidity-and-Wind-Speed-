# -*- coding: utf-8 -*-
"""Temperture_Humidity_wind_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WYif28yzCNhBpsFSavJ35GLLqv0edL-S

# Import the libraries we will need in this Algorithm
"""

import pandas as pd
from datetime import datetime
import seaborn as sns
# Library for build model

import tensorflow as tf
from keras import Sequential
from keras.models import load_model ,save_model
from keras.metrics import MeanSquaredError, MeanAbsoluteError
from keras.layers import Dense, Dropout, LSTM
from keras.regularizers import L1,L2
from keras.optimizers import Adam

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler

from google.colab import drive
drive.mount('/content/drive')

"""# Read Data from two files
## Data for Fayoum Governorate in Egypt from 2012 to 2023, by year, month, day, and hour, and contains temperature, humidity, and wind speed.
"""

df1 = pd.read_csv('/content/drive/MyDrive/Graduation_Project/Data_Fayoum_Weather_Hourly_2012 _2017.csv')
df2 = pd.read_csv('/content/drive/MyDrive/Graduation_Project/Data_Fayoum_Weather_Hourly_2018 _2023.csv')

"""## Merging the two files into one dataset"""

df = pd.concat([df1, df2], axis=0)

df.head()

"""## Change Columns Name To make it easier to deal with"""

df.rename(columns = {"YEAR" : "Year" ,"MO":"Mounth","DY":"Daily","HR":"Hour","T2M":"Temperture","QV2M":"Humidity","WS2M":"Wind_Speed"} , inplace= True)

df

df.info()

df.tail()

"""Search about anu Nulls"""

df.isna().sum()

"""Spearate Data to Test and Train"""

df_test = df[df['Year'] == 2023]
df.drop(df[df['Year']>= 2023].index , inplace = True)

"""## Select Features (X) & Select Target (y)"""

features = ["Year", 'Mounth', "Daily","Hour"]
targets = ["Temperture","Humidity","Wind_Speed"]

X = df[features]
y = df[targets]

print(X)

print(y)

y_columns = y.columns
len(y_columns)

"""## Plot Data ["Temperture","Humidity","Wind_Speed"] to easy understand"""

import matplotlib.pyplot as plt
fig, axes = plt.subplots(nrows=4, ncols=2, dpi=120, figsize=(10, 6))

for i, ax in enumerate(axes.flatten()):
    if i < len(y_columns): # 3 ["Temperture","Humidity","Wind_Speed"]
        data = y[y_columns[i]]
        ax.plot(data, color='red', linewidth=1)
        ax.set_title(y_columns[i])
        ax.xaxis.set_ticks_position('none')
        ax.yaxis.set_ticks_position('none')
        ax.spines["top"].set_alpha(0)
        ax.tick_params(labelsize=6)
    else:
        fig.delaxes(ax)

plt.tight_layout()
plt.show()

"""## Scalar Data from (0-1) to easy deal with

"""

scalar = StandardScaler()
X = pd.DataFrame(scalar.fit_transform(X))

"""# Sperte Data to " x_train, x_val, y_train, y_val " to Train Model"""

x_train, x_val, y_train, y_val = train_test_split(X , y , test_size= 0.3 , random_state = 44 )
# test_size  لازم ارجعها لاتلاته من عشره لانها عملت فرق كبير جداااا في الكفاءه

y_val

y_val.shape

#x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=44)

"""# The code for The Model that performs the process of Training the Algorithm on the data and creating the model with High Efficiency"""

model = Sequential()
model.add(LSTM(32, input_shape = (4, 1), return_sequences=True))
model.add(LSTM(64))

model.add(Dense(128, activation= 'relu'))
model.add(Dense(256, activation= 'relu'))
model.add(Dense(512, activation= 'relu'))
model.add(Dropout(0.2))

model.add(Dense(1024, activation= 'relu'))
model.add(Dense(1024, activation= 'relu'))
model.add(Dense(1024, activation= 'relu'))
model.add(Dense(1024, activation= 'relu'))
model.add(Dense(1024, activation= 'relu'))


model.add(Dense(512, activation= 'relu'))
model.add(Dense(256, activation= 'relu'))
model.add(Dense(128, activation= 'relu'))
model.add(Dense(64, activation= 'relu'))
model.add(Dense(32, activation= 'relu'))

model.add(Dense(3, activation= 'linear'))

model.summary()

model.compile(loss = "mean_squared_error", optimizer=Adam(learning_rate=0.0001) , metrics = [MeanAbsoluteError()])

"""# Step fit() to Train Model "Select Number of Train "
"""

history = model.fit(x_train , y_train ,epochs = 500 ,batch_size = 128 ,validation_data=(x_val , y_val))

train_loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(train_loss) + 1)

len(train_loss)

"""# Plot Relation Between Epochs, Train_Loss"""

plt.plot(epochs, train_loss, label='Training Loss')
plt.plot(epochs, val_loss, label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""# Measure Predicition with " mean_absolute_error , r2_score  "
"""

prediction = model.predict(x_val)

Men = mean_absolute_error(y_val , prediction)
print("MEN",Men)

r2 = r2_score(y_val, prediction)
print(f'r2_score:{r2*100:.2f}%')

#print ("y_val : n\ " , y_val)
#print ("predictionis : n\ " , prediction)

"""## Compare Between y_val "Actual" and Predicition"""

import numpy as np
comparison_table = np.stack((y_val, prediction), axis=1)  # Stack arrays vertically
print('This is comparison_table for predicition & Actual Values : \n ', comparison_table)

"""# Plot to Compare and Expalin  defferent  Actual Data & Perdicition  """

plt.figure(figsize=(16, 4))

for i, target in enumerate(targets, 1):
    plt.subplot(1, 4, i)
    plt.scatter(y_val[target], y_val[target], label='Actual', color='blue', alpha=0.7)
    plt.scatter(y_val[target], prediction [:, i-1], label='Predicted', color='orange', alpha=0.7)
    plt.title(target.capitalize())
    plt.xlabel('Actual')
    plt.ylabel('Predicted')
    plt.legend()

plt.tight_layout()
plt.show()

'''
# Save and Load  Model will run after rise accuracy

import pickle

with open("model_for_prediction_temp_humid_wind", "wb") as file:
    pickel.dump(model,file)

with open('model_pickle','rb') as file:
    mp = pickle.load(file)
'''

"""# Save and Load Model to Test"""

from tensorflow.keras.models import save_model
from tensorflow.keras.models import load_model

save_model(model, 'Model_for_Prediction_Temperature_Humidity_wind_Speed.h5')

loaded_model = load_model('Model_for_Prediction_Temperature_Humidity_wind_Speed.h5')

# Assuming your test data is stored in 'X_test' and labels in 'y_test'
loss, accuracy = loaded_model.evaluate(x_val, y_val)  # For classification tasks
# For regression tasks, you might use a different metric like mean squared error

print('Test loss:', loss)
print('Test accuracy:', accuracy)

import pickle

with open("Model_Prediction_Weather.pkl", "wb") as file:
  pickle.dump(model, file)

with open("Model_Prediction_Weather.pkl", "rb") as file:
    loaded_model = pickle.load(file)

